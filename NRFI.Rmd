---
title: "NRFI Prediction Model"
author: "Bryan Jacobs\nAiden Fletcher"
date: "2025-08-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## NRFI Prediction Model

Goal: Predict the probability of the occurrence of a No Run First Inning given any MLB match up.

Data Set: baseballr

Model: XGBoost

Pull data from baseballr using R

potentially cleaning / feature engineering

```{r}
# Load Packages
if (!requireNamespace('pacman', quietly = TRUE)){
  install.packages('pacman')
}
pacman::p_load_current_gh("BillPetti/baseballr")

pacman::p_load(tidyverse,
               reticulate,
               purrr,
               furrr,
               future)
```

```{r}
# Safe wrappers
safe_linescore <- safely(mlb_game_linescore)
safe_gameinfo  <- safely(mlb_game_info)
safe_probables <- safely(mlb_probables)
safe_game_pks <- safely(mlb_game_pks)

# Parallel plan: use all but 1 core
plan(multisession, workers = parallel::detectCores() - 1)

# Acquire game pk's ##########################################################################
# Define date range (last 6 seasons)
start_date <- as.Date("2019-03-01")  # start of 2019 season
end_date <- as.Date("2024-11-01")    # end of 2024 season

# Create sequence of dates
dates <- seq.Date(start_date, end_date, by = "day") %>%
  .[month(.) %in% 3:10]  # MLB regular season roughly March-October

# Get game PKs in parallel
game_pks <- future_map_dfr(dates, function(date) {
  res <- safe_game_pks(as.character(date), level_ids = c(1))
  if (!is.null(res$result)) {
    return(res$result)
  } else {
    return(NULL)
  }
}, .progress = TRUE)

# Remove duplicates and select pk vector
game_ids <- distinct(game_pks, game_pk) %>% pull(game_pk)

# Fetch inning-by-inning data ################################################################
# Fetch inning-by-inning data in parallel
all_games_data <- future_map_dfr(game_ids, ~ safe_linescore(.x)$result, .progress = TRUE)


# Filter to inning 1, keep only pre-game predictors + outcome vars for target creation
inning_1_data <- all_games_data %>%
  filter(num == 1) %>%
  select(game_pk, 
         num, 
         home_team_name, 
         away_team_name,
         home_runs,  # will be used for NRFI target
         away_runs,
         home_team_record_wins, 
         away_team_record_wins)

# Fetch weather data #########################################################################
# Fetch weather data in parallel
weather_data <- future_map_dfr(game_ids, function(id) {
  res <- safe_gameinfo(id)
  df <- res$result
  if (!is.null(df)) {
    # Force attendance to character to avoid type conflicts
    if ("attendance" %in% names(df)) {
      df$attendance <- as.character(df$attendance)
    }
    return(df)
  } else {
    return(NULL)
  }
}, .progress = TRUE)


# Clean and rename to avoid collisions
weather_data_clean <- weather_data %>%
  select(game_pk,
         venue_name,
         temp_game = temperature,
         weather = other_weather)

# Fetch starting pitcher data ###############################################################
# Fetch pitcher data in parallel
pitcher_data <- future_map_dfr(game_ids, ~ safe_probables(.x)$result, .progress = TRUE)

# Extract home and away teams from original data
game_teams = all_games_data %>%
  select(game_pk,
         home_team_id,
         away_team_id)

# Join pitcher data with game_teams on game_pk
pitcher_with_side <- pitcher_data %>%
  left_join(game_teams, by = "game_pk") %>%
  mutate(home_away = case_when(
    team_id == home_team_id ~ "home",
    team_id == away_team_id ~ "away",
    TRUE ~ NA_character_
  ))

# Split pitchers to home and away
home_pitchers <- pitcher_with_side %>%
  filter(home_away == "home") %>%
  select(game_pk, home_team_name = team, home_pitcher_name = fullName)

away_pitchers <- pitcher_with_side %>%
  filter(home_away == "away") %>%
  select(game_pk, away_team_name = team, away_pitcher_name = fullName)

# Extract unique rows
home_pitchers_unique <- home_pitchers %>%
  group_by(game_pk, home_team_name) %>%
  slice(1) %>%  # keep only first row per group
  ungroup()

away_pitchers_unique <- away_pitchers %>%
  group_by(game_pk, away_team_name) %>%
  slice(1) %>%
  ungroup()


# Join, create NRFI target, drop leak columns ################################################
inning_1_final <- inning_1_data %>%
  left_join(weather_data_clean, by = "game_pk") %>%
  left_join(home_pitchers_unique, by = c("game_pk", "home_team_name")) %>%
  left_join(away_pitchers_unique, by = c("game_pk", "away_team_name")) %>%
  mutate(NRFI = as.integer(home_runs == 0 & away_runs == 0)) %>%
  select(-home_runs, -away_runs, -game_pk, -num)

# write final data to a csv
write.csv(inning_1_final, "inning_1_data.csv", row.names = FALSE)
```

model creation, training, testing, optimizing in Python (switching to real python IDE)

```{python}
# Load packages
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
import joblib
```

```{python}
# ===== Step 1: Load CSV =====
df = pd.read_csv("inning_1_data.csv")

# ===== Step 2: Separate features (X) and target (y) =====
X = df.drop(columns=["NRFI"])
y = df["NRFI"]

# ===== Step 3: Identify categorical & numeric columns =====
categorical_cols = X.select_dtypes(include=["object", "category"]).columns
numeric_cols = X.select_dtypes(exclude=["object", "category"]).columns

# ===== Step 4: Build preprocessing =====
preprocessor = ColumnTransformer(
    transformers=[
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_cols),
        ("num", "passthrough", numeric_cols)
    ]
)

# ===== Step 5: Create pipeline with XGBoost =====
model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", XGBClassifier(
        objective="binary:logistic",
        eval_metric="logloss",
        use_label_encoder=False
    ))
])

# ===== Step 6: Train/test split =====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ===== Step 7: Train =====
model.fit(X_train, y_train)

# ===== Step 8: Evaluate =====
y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"Accuracy: {acc:.2f}")
```

```{python}
# Save trained model to avoid retraining
joblib.dump(model, "xgb_game_model.pkl")
```

```{python}
# Streamlit Web App
# Load model
model = joblib.load("xgb_game_model.pkl")

st.title("Game Outcome Predictor")

# Example input variables
home_team = st.selectbox("Home Team", ["Yankees", "Dodgers", "Cubs"])
away_team = st.selectbox("Away Team", ["Yankees", "Dodgers", "Cubs"])
temperature = st.slider("Temperature (Â°F)", 30, 100)
wind_speed = st.slider("Wind Speed (mph)", 0, 20)

# Create dataframe for prediction
input_df = pd.DataFrame({
    "home_team": [home_team],
    "away_team": [away_team],
    "temperature": [temperature],
    "wind_speed": [wind_speed]
})

if st.button("Predict"):
    prediction = model.predict(input_df)[0]
    st.write(f"Predicted outcome: {prediction}")
```

```{bash}
# Run App
streamlit run app.py
```
